{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler,Imputer\n",
    "\n",
    "# from sklearn import metrics\n",
    "# from scipy import spatial\n",
    "import statistics\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln=math.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'case_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'case_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8eeaf6d6265e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Kaggle dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"big_five_scores_modified.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"case_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Age'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Sex\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Agreeableness\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Extraversion\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Openness\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Conscientiousness\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Neuroticism\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Skills\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Looking for\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Languages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mto_pop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sex\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4507\u001b[0m         \u001b[0;36m3\u001b[0m  \u001b[0mmonkey\u001b[0m        \u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4508\u001b[0m         \"\"\"\n\u001b[0;32m-> 4509\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4511\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'case_id'"
     ]
    }
   ],
   "source": [
    "# Kaggle dataset\n",
    "df=pd.read_csv(\"big_five_scores_modified.csv\",delimiter=\";\")\n",
    "df.pop(\"case_id\")\n",
    "df.columns=['Country', 'Age',\"Sex\",\"Agreeableness\",\"Extraversion\",\"Openness\",\"Conscientiousness\",\"Neuroticism\",\"Skills\",\"Looking for\",\"Languages\"]\n",
    "to_pop=[\"Sex\"]\n",
    "for i in to_pop:\n",
    "    df.pop(i)\n",
    "df=df.drop(df.index[1000:])\n",
    "df.head()\n",
    "# # Seb's dataset\n",
    "# fake_users=pd.read_csv(\"10_personalities.csv\",delimiter=\";\")\n",
    "# connections=pd.read_csv(\"connections_data.csv\")\n",
    "# print(fake_users.head())\n",
    "\n",
    "fake_users=df\n",
    "fake_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Looking for</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>Web Design, Back-End Development</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>25</td>\n",
       "      <td>Back-End Development, Web design</td>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>85</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>Branding, Risk Assessment</td>\n",
       "      <td>Leadership, Communication, Powerpoint</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>35</td>\n",
       "      <td>65</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>Coaching, Design, Web Design,</td>\n",
       "      <td>Mobile Development, UI/UX</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>Online Marketing, Design, UI/UX</td>\n",
       "      <td>Software Engineering, Back-end development, ac...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Openness  Conscientiousness  Extraversion  Agreeableness  Neuroticism  \\\n",
       "0        25                 25            75             75           25   \n",
       "1        75                 25            85             85           25   \n",
       "2        45                 85            45             25           25   \n",
       "3        75                 35            65             25           25   \n",
       "4        75                 35            25             45           65   \n",
       "\n",
       "                              Skills  \\\n",
       "0                      Data Analysis   \n",
       "1  Back-End Development, Web design    \n",
       "2          Branding, Risk Assessment   \n",
       "3     Coaching, Design, Web Design,    \n",
       "4    Online Marketing, Design, UI/UX   \n",
       "\n",
       "                                         Looking for Language  \n",
       "0                   Web Design, Back-End Development  English  \n",
       "1                                      Data Analysis  English  \n",
       "2              Leadership, Communication, Powerpoint   French  \n",
       "3                          Mobile Development, UI/UX  Chinese  \n",
       "4  Software Engineering, Back-end development, ac...   German  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_users=pd.read_csv(\"../data/raw/BAZREVISEDPERSONAS.csv\",delimiter=\";\")\n",
    "# to_pop=[\"Predicted Match from OCEAN\"]\n",
    "# for i in to_pop:\n",
    "#        fake_users.pop(i)\n",
    "# fake_users.columns=[\"Openness\",\"Conscientiousness\",\"Extraversion\",\"Agreeableness\",\"Neuroticism\",\"Skills\",\"Looking for\"]\n",
    "fake_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "big5=[\"Openness\",\"Conscientiousness\",\"Extraversion\",\"Agreeableness\",\"Neuroticism\"]\n",
    "\n",
    "\n",
    "for i in big5:\n",
    "    fake_users[i]*=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_users[\"Neuroticism\"]=1-fake_users[\"Neuroticism\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.75\n",
       "1    0.75\n",
       "2    0.75\n",
       "3    0.75\n",
       "4    0.35\n",
       "5    0.25\n",
       "6    0.85\n",
       "7    0.50\n",
       "8    0.25\n",
       "9    0.85\n",
       "Name: Neuroticism, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_users[\"Neuroticism\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best matches for user 7 are:\n",
      "[(2, 0.8881298369060315), (9, 0.8645311425790803), (0, 0.8440084612896078), (3, 0.7787987964520333), (6, 0.7212515175246317), (1, 0.6701766380034315), (5, 0.6496653350663693), (4, 0.617483322707487), (8, 0.6082350942223472)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "class Recommendation:\n",
    "    def __init__(self,user_id,df):\n",
    "        self.big5=[\"Extraversion\",\"Agreeableness\",\"Conscientiousness\",\"Neuroticism\",\"Openness\"]\n",
    "        self.importance_index={\"Openness\":0.7,\"Extraversion\":0.3,\"Agreeableness\":0.5,\"Neuroticism\":0.4,\"Conscientiousness\":0.6}\n",
    "        self.reverse_threshold=50    \n",
    "        self.df=df\n",
    "#         self.connections=connections\n",
    "        self.overall_scores={}\n",
    "        self.user_id=user_id\n",
    "\n",
    "\n",
    "    \n",
    "    def get_recommendations_list(self,n):\n",
    "        \"\"\"\n",
    "        input:the number of first elements\n",
    "        outputs: sorted dictionary with similarity scores between target user and each other user\n",
    "        \"\"\"\n",
    "        \n",
    "        recommendation=self.main_recommender(self.user_id,self.overall_scores,self.df)\n",
    "        sorted_recommendation=self.sorted_dictionary(recommendation)\n",
    "        return self.take(n,sorted_recommendation.items())\n",
    "\n",
    "    def take(self,n, iterable):\n",
    "        \"Return first n items of the iterable as a list\"\n",
    "        return list(islice(iterable, n))\n",
    "        \n",
    "\n",
    "\n",
    "    def sorted_dictionary(self,dictionary):\n",
    "        \"\"\"\n",
    "        Returns sorted dictionary \n",
    "        \"\"\"\n",
    "        return {k: v for k, v in sorted(dictionary.items(), key=lambda item: item[1],reverse=True)}\n",
    "    def main_recommender(self,user_id,overall_scores,df):\n",
    "        \"\"\"\n",
    "        input: user_id (integer), targeted_skills (list), personality_traits (dictionary)\n",
    "        outputs: people suggestions as a dictionary with score\n",
    "        \"\"\"\n",
    "    #   load the dataset \n",
    "        self.personality_language_age(df)\n",
    "        self.skills_analyser(df)\n",
    "#         self.count_mutual_connections()\n",
    "        \n",
    "        return self.overall_scores\n",
    "\n",
    "\n",
    "    def personality_language_age(self,df):\n",
    "        \"\"\"\n",
    "        input: df (pandas dataframe), personality traits (list)\n",
    "        outputs: dictionary {user_index:mean_difference}\n",
    "        \"\"\"\n",
    "#       Split the language\n",
    "#         example_user_language=ast.literal_eval(fake_users.loc[self.user_id][\"Languages\"])\n",
    "        example_user_language=fake_users.loc[self.user_id][\"Language\"]\n",
    "\n",
    "\n",
    "#         example_user_age=fake_users.loc[self.user_id][\"Age\"]\n",
    "#         example_user_country=fake_users.loc[self.user_id][\"Country\"]\n",
    "#         common_language=False\n",
    "            # Cosine similarity\n",
    "        user_qualities={}\n",
    "        # Filling our user qualities\n",
    "        for i in self.big5:\n",
    "            user_qualities[i]=self.df.loc[self.user_id][i]\n",
    "        users_mean_difference=[]\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            mean_difference=0\n",
    "            if index!=self.user_id:\n",
    "                \n",
    "                \n",
    "#             Create the list of the user languages\n",
    "                current_user_language=row[\"Language\"]\n",
    "#                 current_user_language=ast.literal_eval(row[\"Languages\"])\n",
    "\n",
    "    \n",
    "#                 current_user_country=row[\"Country\"]\n",
    "#                 current_user_age=row[\"Age\"]\n",
    "#                 Find the age difference\n",
    "#                 age_difference=abs(example_user_age-current_user_age)\n",
    "                for i in self.big5:\n",
    "                    row_trait=row[i]\n",
    "                    users_trait=user_qualities[i]\n",
    "                    difference=0\n",
    "#                 Keep track of counted rows\n",
    "                    counted=False\n",
    "\n",
    "# Check if the user quality is more than 40. Else, make a reverce relationship\n",
    "#                     if user_qualities[i]<40 or row[i]<40:\n",
    "                        \n",
    "#                         difference+=abs(ln(row_trait/users_trait))*self.importance_index[i]\n",
    "#                         mean_difference+=(1-difference)\n",
    "#                         counted=True\n",
    "                    if not counted:\n",
    "\n",
    "                        mean_difference+=abs(ln(row_trait/users_trait))*self.importance_index[i]\n",
    "\n",
    "                mean_difference/=len(self.big5)\n",
    "                \n",
    "#                 Store the final reverse mean difference (the bigger the better) in the dictionary\n",
    "                self.overall_scores[index]=(1-mean_difference)\n",
    "#                 if example_user_language!=current_user_language:\n",
    "#                     self.overall_scores[index]*=0.7\n",
    "                \n",
    "#                 for i in example_user_language:\n",
    "\n",
    "#                     if i in current_user_language:\n",
    "\n",
    "\n",
    "#                         common_language=True\n",
    "\n",
    "#                 if common_language==False:        \n",
    "#                     self.overall_scores[index]=int(self.overall_scores[index])*0.7\n",
    "                \n",
    "# #                 Check the country\n",
    "#                 if current_user_country!=example_user_country:\n",
    "#                     self.overall_scores[index]*=0.8\n",
    "                \n",
    "        return self.overall_scores\n",
    "    \n",
    "    def skills_analyser(self,df):\n",
    "#         example_user_skills=ast.literal_eval(fake_users.loc[self.user_id][\"Skills\"])\n",
    "        example_user_skills=self.df.loc[self.user_id][\"Skills\"].split(\",\")\n",
    "#         looking_for_skills=ast.literal_eval(fake_users.loc[self.user_id][\"Looking for\"])\n",
    "        looking_for_skills=self.df.loc[self.user_id][\"Looking for\"].split(\",\")\n",
    "\n",
    "\n",
    "        # get the targeted skills lost\n",
    "        targeted_skills=[]\n",
    "        # Delete the final comma \n",
    "        del example_user_skills[-1]\n",
    "        user_skills_list=[]\n",
    "        \n",
    "        for index,row in fake_users.iterrows():\n",
    "            \n",
    "            if index!=self.user_id:\n",
    "                current_user_skills=row[\"Skills\"].split(\",\")\n",
    "                current_user_looking_for=row[\"Looking for\"].split(\",\")\n",
    "\n",
    "#                 Delete the final comma\n",
    "                del current_user_skills[-1]\n",
    "#     Finding the similarities between two lists\n",
    "                similarities_xy=set(looking_for_skills) & set(current_user_skills)\n",
    "                similarities_yx=set(current_user_looking_for) & set(example_user_skills) \n",
    "#     Calculating a similarity percentage(score)\n",
    "                similarity_xy=len(similarities_xy)/len(looking_for_skills)\n",
    "                similarity_yx=len(similarities_yx)/len(current_user_looking_for)\n",
    "                similarities=statistics.mean([similarity_xy,similarity_yx])\n",
    "\n",
    "#                 similarities=set(example_user_skills) & set(curent_user_looking_for)\n",
    "                user_skills_list.append([index,similarities])\n",
    "                self.overall_scores[index]+=similarities\n",
    "                \n",
    "\n",
    "\n",
    "        return self.overall_scores\n",
    "\n",
    "#     def count_mutual_connections(self):\n",
    "#         \"\"\"\n",
    "#         input:user_id (integer), connections datafraem\n",
    "#         output: dictionary {user_index:number_of mutual connections}\n",
    "#         \"\"\"\n",
    "\n",
    "\n",
    "#         user_connections=[]\n",
    "#         print(self.connections.head())\n",
    "\n",
    "\n",
    "#         for index, row in self.connections.iterrows():\n",
    "#             if row[\"connection_initiator\"]==self.user_id and row[\"connection\"]!=self.user_id:\n",
    "#                 user_connections.append(row[\"connection\"])\n",
    "#             if row[\"connection\"]==self.user_id and row[\"connection_initiator\"]!=self.user_id:\n",
    "#                 user_connections.append(row[\"connection_initiator\"])\n",
    "            \n",
    "#         mutual_connections={}\n",
    "#         for index, row in self.connections.iterrows():\n",
    "#             for i in user_connections:\n",
    "#                 if i==row[\"connection\"] and i!=self.user_id and row[\"connection_initiator\"]!=self.user_id:\n",
    "#                     try:\n",
    "#                         mutual_connections[row[\"connection_initiator\"]]+=1\n",
    "#                     except KeyError:\n",
    "#                         mutual_connections[row[\"connection_initiator\"]] =1\n",
    "#                 if i==row[\"connection_initiator\"] and i!=self.user_id and row[\"connection\"]!=self.user_id:\n",
    "#                     try:\n",
    "#                         mutual_connections[row[\"connection\"]]+=1\n",
    "#                     except KeyError:\n",
    "#                         mutual_connections[row[\"connection\"]] = 1\n",
    "# #         print(mutual_connections)\n",
    "#         for key,value in mutual_connections.items():\n",
    "#             # add all connections to the overall score\n",
    "#             if key<len(self.df):\n",
    "#                 self.overall_scores[key]+=value\n",
    "#         return (self.overall_scores)\n",
    "\n",
    "\n",
    "recommender=Recommendation(7,fake_users)\n",
    "listrec=recommender.get_recommendations_list(9)\n",
    "print(\"The best matches for user {} are:\\n\".format(recommender.user_id)+ str(recommender.get_recommendations_list(9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openness                                       0.75\n",
      "Conscientiousness                              0.35\n",
      "Extraversion                                   0.65\n",
      "Agreeableness                                  0.25\n",
      "Neuroticism                                    0.75\n",
      "Skills               Coaching, Design, Web Design, \n",
      "Looking for               Mobile Development, UI/UX\n",
      "Language                                    Chinese\n",
      "Name: 3, dtype: object\n",
      "Openness                                                         0.25\n",
      "Conscientiousness                                                 0.7\n",
      "Extraversion                                                     0.75\n",
      "Agreeableness                                                    0.75\n",
      "Neuroticism                                                       0.5\n",
      "Skills               Leadership, Power point, Coaching, Communication\n",
      "Looking for                     Risk Assessment, Web Design, Branding\n",
      "Language                                                       French\n",
      "Name: 7, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(fake_users.iloc[listrec[1][0]])\n",
    "print(fake_users.iloc[recommender.user_id])\n",
    "# print(df.loc[[60]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Looking for</th>\n",
       "      <th>Languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>45</td>\n",
       "      <td>0.763333</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>['AWS', 'Premiere Pro', 'Digital Marketing', '...</td>\n",
       "      <td>['Accounting', 'PR']</td>\n",
       "      <td>['French', 'English']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Agreeableness  Extraversion  Openness  Conscientiousness  \\\n",
       "70   45       0.763333      0.523333      0.76           0.806667   \n",
       "\n",
       "    Neuroticism                                             Skills  \\\n",
       "70     0.856667  ['AWS', 'Premiere Pro', 'Digital Marketing', '...   \n",
       "\n",
       "             Looking for              Languages  \n",
       "70  ['Accounting', 'PR']  ['French', 'English']  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(listrec[0][0]+1).tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Looking for</th>\n",
       "      <th>Languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>45</td>\n",
       "      <td>0.763333</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>['AWS', 'Premiere Pro', 'Digital Marketing', '...</td>\n",
       "      <td>['Accounting', 'PR']</td>\n",
       "      <td>['French', 'English']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Agreeableness  Extraversion  Openness  Conscientiousness  \\\n",
       "70   45       0.763333      0.523333      0.76           0.806667   \n",
       "\n",
       "    Neuroticism                                             Skills  \\\n",
       "70     0.856667  ['AWS', 'Premiere Pro', 'Digital Marketing', '...   \n",
       "\n",
       "             Looking for              Languages  \n",
       "70  ['Accounting', 'PR']  ['French', 'English']  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(recommender.user_id+1).tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DJ_recommender_system",
   "language": "python",
   "name": "dj_recommender_system"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
